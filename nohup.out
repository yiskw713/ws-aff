nohup: ignoring input
  0%|          | 0/23074 [00:00<?, ?it/s]drn_c_58_maxwill be used
Success

Traceback (most recent call last):
  File "generate_cam_label.py", line 100, in <module>
    main()
  File "generate_cam_label.py", line 95, in main
    for sample in tqdm.tqdm(train_loader, total=len(train_loader)):
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/tqdm/_tqdm.py", line 1000, in __iter__
    for obj in iterable:
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 637, in __next__
    return self._process_next_batch(batch)
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 658, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
ValueError: Traceback (most recent call last):
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 138, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/yuchi/Documents/ws-aff/dataset.py", line 56, in __getitem__
    sample = self.transform(sample)
  File "/home/yuchi/.pyenv/versions/torch/lib/python3.6/site-packages/torchvision/transforms/transforms.py", line 49, in __call__
    img = t(img)
  File "/home/yuchi/Documents/ws-aff/dataset.py", line 241, in __call__
    sample['image'], sample['obj_label'], sample['aff_label']
ValueError: not enough values to unpack (expected 4, got 3)


